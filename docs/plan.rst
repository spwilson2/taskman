Planning Document
=================

This document contains various thoughts that are going into the planning of
Taskman.

Taskman will be split into two separate processes, frontend and baackend.

The frontend will obviously be in charge of interacting with the user in some
manner (up to the frontend implementation to design the interface).

The backend will:
- Maintain handles to active subprocess tasks running
- Maintain the "official" DAG
- Schedule tasks


In order to maintain this split and allow backend and frontend freedom of
implementation, we will define a strict API here. Before we do so though, we
will first need a general description of the common state between both
frontend and backend.

What is Taskman?
================

Taskman at its core is a task scheduler. It contains a heirarchy of tasks
to run and runs them in order as soon as there are no impeding tasks further
up the heirarchy preventing them from running. (This enables certain
non-traditonal tasks such as system conditions, if/else statemnts to modify or
conditonally delay execution of tasks.)


Frontend Requirements
---------------------

The frontend is going to want to:

- Query the Backend for DAG heirarchy - (This could be pagenated, won't be
  for now)
- (Un/)Subscribe for updates - NOTE non-RESTful, will need to use a pubsub
  service.
- Modify existing tasks (e.g. change command args)
- Add and Remove nodes/chains from the DAG

- Get currently running tasks.
- Kill currently running tasks.



API Endpoints
=============

Taskman is probably best understood through the api's it offers and the
format used when talking about its internal state via HTTP endpoints. Here
we discuss those.

This documents the v1 api, all endpoints should begin with ``/v1/``.

TODO Change the apis to accessors of parts of nodes e.g.


Pagination
----------

Some APIs support pagination of requests. This API uses URI parameters to
enable pagination.

Requests to pagination enabled APIs can continue as normal. Requsts which will
receive additional data via paginated requests will receive the following
additional data in JSON responses::

    pagination: {
        next: "<value-to-use-in-next-request>",
        pid: "<value-to-use-in-next-request>"
    }

- ``next`` - should be passed as an addiitonal query parameter in additonal
  requests as ``start``
- ``pid`` - must be passed as a parameter with ``start`` to ensure pagination
  is still valid

Nodes
-----

/nodes - GET - Get high level information about many nodes at once

Parameters:
- (o) type - Type of nodes ids to return
- (o) state - Status of node ids to return, if not supplied nodes of all
  state types will be returned
- (o) metadata - Comma separated list of metadata to provide with the nodes,
  (in addition to ID) if not supplied, all metadata will be returned
- (o) new=<id> - Return only nodes newer than the given id, if none are newer
  the request will wait until the client times out or one or more nodes are
  added

Example response to ``GET /nodes?metadata=type,parent``::

    [
        {
            id: "22",
            type: "command",
            parent: "root",
        },
        {
            id: "23",
            type: "command",
            parent: "22",
        }
    ]

Pagination is supported for this interface.

-----

/nodes - POST - Add a new node with given metadata & data

Node should be formatted as follows (multiple can be submitted at the same time)::

    [
        {
            metadata: {
                type: "<any-supported-type>",
                parent: "<root | an existing node ID>"
                // An ID will be automatically generated by the server
                // The task will automatically be place in the incipient state
            }
            data: {
            }
        } //, Optional additional nodes
    ]

-----

/nodes/<id>/data - GET - Returns a list of data keys

Response format::
    {
        keys: [
            "a", "list", "of", "keys" 
        ]
    }

Pagination is supported for this interface.

-----

/nodes/<id>/data/<key> - GET - Returns data for the given key

Pagination is supported for this interface.

Response format::
    
    {
        key: "<key>",
        data: "<data>",
        pagination: {
            next: "<value-to-use-in-next-request>",
            pid: "<value-to-use-in-next-request>"
        }
    }

-----

/nodes/<id>/data/<key> - PUT - Replace data values

Expected request format::

    {
        value: "<data>",
    }

Pagination is supported for this interface, however it is a bit special.
The ``start`` parameter is optional. If it is provided but without a value then
PUT will only replace the current value if the value for ``<key>`` is unset.
The ``pagid`` value and ``start`` value to replace the first slot of data will
be returned in the response. Otherwise, pagination behaves as you would expect.

-----


Scheduler
---------

Scheduler APIs are sort of non-RESTful interfaces to simplify application
development.

-----

/scheduler/kill - PUT - Start the kill process for the given processes

Parameters:
- id - Comma separated list of tasks to inform the scheduler to begin killing

-----

/scheduler/wait - GET - Wait for <id>'s node to finish execution, returns the
    node's state on completion

Parameters:
- id - Comma separated list of tasks which will be waited on, GET response is
  received when all tasks are in a terminal state


Node Types
----------

Command Node
~~~~~~~~~~~~

This node is a command which will be executed by python. It is formatted as
follows::

    {
        metadata: {
            id: "123",
            type: "command",
        },
        data: {
            command: "echo",
            args: ["hello", "world"],
            result: 0,

            stdout: "hello world",
            stderr: "",
            mixedout: "hello world"
        }
    }

Shell Command Node
~~~~~~~~~~~~~~~~~~

This node is similar to the ``Command Node`` except that it will run the command
in a bash shell.

Format::

    {
        metadata: {
            id: "123",
            type: "shell command",
            status: "finished"
        },
        data: {
            command: "echo hello world",
            result: 0,

            stdout: "hello world",
            stderr: "",
            mixedout: "hello world"
        }
    }


Taskman's Scheduler
===================

The task scheduler maintains a list of top level tasks which have not yet
completed. The scheduler spins in a loop waiting for any task in this list to
either complete or become schedulable. If a task completes, that completed
task will be taken off the queue and any direct children will be placed in
the top level list. If a task becomes scheduleable, (e.g. a new task is added
to the top level list) then the scheduler will start the task using a
separate thread, mark the task as running, and then the scheduler will
continue through the list.

Here's psuedocode of this process::

    while True:
        for task in unscheduled_list:
            if task.state == "complete":
                cleanup_task_thread(task)
                # psuedocode, iteration modification danger
                unscheduled_list.remove(task)
                unscheduled_list.extend(task.subtasks)

            if schedulable(task.state):
                start_task_thread(task)



TODO Task completion flow:

NOTE: Each task should get modification access to its parent task and its
subtasks.

Task Lifetime
-------------

Tasks are created via the ``/nodes`` api endpoint by the frontend. Tasks
created via this method will begin in the ``incipient`` state. 


Lifetime Flow:

- Created via ``/nodes`` POST call
- (If) task is a top level task it is added to the scheduler top level list
- Scheduler starts the task in a separate thread
- Task finishes..

